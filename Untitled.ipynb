{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort import preprocessing\n",
    "from deep_sort.detection import Detection\n",
    "from deep_sort.tracker import Tracker\n",
    "from mgn.network import MGN\n",
    "# from coordinate_transform import CoordTrans\n",
    "from mgn.utils.extract_feature import extract_feature\n",
    "from yolo import YOLO\n",
    "from utils.util import checkPoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_pytorch(model_path):\n",
    "    model = MGN()\n",
    "    model = model.to('cuda')\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model\n",
    "\n",
    "#保存检测过程中的bbox\n",
    "def box_encode(model, img, boxes=None, prefix='./img1/'):\n",
    "    if boxes == None:\n",
    "        boxes = []\n",
    "        boxes.append([0,0, img.size[0], img.size[1]])\n",
    "    imgs = []\n",
    "#     print(img.size)\n",
    "    for box in boxes:\n",
    "        _box = box.copy()\n",
    "        _box[2] = _box[0] + _box[2]\n",
    "        _box[3] = _box[1] + _box[3]\n",
    "        imgs.append(img.crop(_box))\n",
    "#         print(img.crop(_box).size)\n",
    "\n",
    "    # img.save(os.path.join(prefix, 'raw.jpg'), quality=95)\n",
    "    # for idx, x in enumerate(imgs):\n",
    "    #     x.save(os.path.join(prefix, 'box'+str(idx)+'.jpg'), quality=95)\n",
    "\n",
    "    model.eval()\n",
    "    features = torch.FloatTensor()\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((384, 128), interpolation=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    for _img in imgs:\n",
    "        _img = test_transform(_img)\n",
    "        query_feature = extract_feature(model, [(torch.unsqueeze(_img, 0), 1)])\n",
    "        features = torch.cat((features, query_feature), 0)\n",
    "    return features.numpy()\n",
    "_model = load_model_pytorch('/home/lyz/Desktop/ReID-MGN/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './source/1.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "out = box_encode(_model, Image.fromarray(img[...,::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2048) [[0.00229122 0.04694302 0.01157228 ... 0.05349796 0.02970668 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(out.shape, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
